# Detailed Project Explanation  
## Codveda Internship Tasks Breakdown  

This repository contains all tasks completed during my internship at Codveda Technologies. Each level represents increasing complexity â€” from foundational Python programming to structured data analysis and advanced problem-solving.

---

## ğŸ¢ Internship Overview

This project was completed as part of a structured internship program at Codveda Technologies, where tasks were grouped into three progressive levels:

- **Level 1 â€” Basic**
- **Level 2 â€” Intermediate**
- **Level 3 â€” Advanced**

The goal was to strengthen programming fundamentals, data handling skills, and analytical thinking using Python and related tools.

---

# ğŸ”¹ Level 1 â€” Basic Tasks

These tasks focused on strengthening core Python fundamentals.

---

## âœ… Level1-Basic_Task1.py  
**Description:** Collect data from a website using web scraping techniques  

**What It Covers:**
- Using BeautifulSoup and requests libraries to scrape data from web pages.
- Storing the scraped data in a structured format (e.g., CSV, JSON).
- Handling common challenges such as pagination and dynamic content 

**Purpose:**  
To learn understand data collection and web scraping.

---

## âœ… Level1-Basic_Task2.ipynb  
**Description:** Clean and preprocess a raw dataset to make it suitable for analysis.  

**What It Covers:**
- Handling missing data (e.g., imputation, removal).
- Detecting and removing outliers from data.
- Converting categorical variables into numerical format using one-hot encoding or label encoding.
- Normalising or standardising numerical data.

**Purpose:**  
To put data cleaning and preprocessing into practice.

---

## âœ… Level1-Basic_Task3.ipynb  
**Description:** Perform exploratory data analysis to understand the underlying structure and trends in the data.  

**What It Covers:**
- Computing some summary statistics like mean, median, variance, etc.
- Visualising the data using suitable visualisation like histograms, scatter plots, and box plots.
- Identifying correlations between numerical features using a correlation matrix.

**Purpose:**  
To understand exploratory data analysis (EDA).

---

# ğŸ”¹ Level 2 â€” Intermediate Tasks

These tasks introduced data analysis and more structured programming concepts.

---

## ğŸ“Š Level2-Intermediate_Task1.ipynb  
**Description:** Build and evaluate a regression model to predict a continuous variable.

**What It Covers:**
- Spliting the dataset into training and testing sets.
- Training a linear regression model using scikit-learn.
- Evaluating the model using performance metrics like mean squared error (MSE) and R-squared.
- Comparing and experimenting with multiple models like Decision Trees, Random Forest, etc. and comparing performance also.

**Purpose:**  
To understand how to perform predictive modelling and selecting the best model to use.

---

## ğŸ“Š Level2-Intermediate_Task2.ipynb  
**Description:** Build a decision tree classifier to predict a categorical outcome.

**What It Covers:**
- Preprocessing the data which involves handling categorical features, feature scaling, etc.
- Training and evaluating the logistic regression model.
- Using metrics such as accuracy, precision, recall, and the ROC curve for evaluation.
- Comparing logistic regression with other classifiers like
Random Forest or SVM.

**Purpose:**  
To undering classification using Logistic regression and also determine the best model by comparison.

---

## ğŸ“Š Level2-Intermediate_Task3.ipynb  
**Description:** Implement K-Means clustering to group data points into clusters without labels.

**What It Covers:**
- Applying K-Means clustering to the dataset.
- Using the elbow method or silhouette score to determine the optimal number of clusters.
- Visualising the clusters in 2D space using PCA or t-SNE for dimensionality reduction.

**Tools Used:**
- Pandas
- Scikit-learn
- Matplotlib / Seaborn

**Purpose:**  
To understand clustering and details knowledge of knowing the numbers of optimal clusters in the dataset.

---

# ğŸ”¹ Level 3 â€” Advanced Tasks

These tasks required deeper analytical thinking and structured problem-solving.

---

## ğŸ§  Level3-Advanced_Task1.ipynb  
**Objective:** Complex data manipulation and logic building.  

**What It Covers:**
- Advanced filtering techniques  
- Multi-step data transformation  
- Combining multiple datasets  

**Purpose:**  
To simulate real-world data workflows.

---

## ğŸ§  Level3-Advanced_Task2.ipynb  
**Objective:** Advanced analysis and insight generation.  

**What It Covers:**
- Deeper statistical exploration  
- Pattern recognition  
- Analytical conclusions  

**Purpose:**  
To move from data handling to decision-support analysis.

---

## ğŸ§  Level3-Advanced_Task3.ipynb  
**Objective:** Full analytical workflow.  

**What It Covers:**
- Data loading  
- Cleaning  
- Analysis  
- Visualization  
- Conclusion  

**Purpose:**  
To demonstrate end-to-end project execution skills.

---

# ğŸ›  Technologies Used

- Python  
- Jupyter Notebook  
- Pandas  
- NumPy  
- Matplotlib  
- Seaborn  

---

# ğŸš€ Project Repository

This project is hosted on GitHub and serves as a structured showcase of my internship progress and technical development.

Repository: Codveda-Project  
Platform: GitHub  

---

# ğŸ¯ Skills Demonstrated

- Python programming fundamentals  
- Data cleaning and preprocessing  
- Exploratory Data Analysis (EDA)  
- Data visualization  
- Logical thinking and structured problem-solving  
- End-to-end analytical workflow development  

---

# ğŸ“Œ Conclusion

This internship project represents a progressive learning journey â€” from writing basic Python scripts to executing structured, real-world data analysis workflows.

It demonstrates both technical growth and the ability to apply programming skills to practical tasks.
